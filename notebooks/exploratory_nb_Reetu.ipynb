{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from functions import *\n",
    "import seaborn as sns\n",
    "# raw data\n",
    "df_clients_profile = pd.read_csv('../Data/Raw/df_final_demo.txt')\n",
    "df_web_data_1 = pd.read_csv('../Data/Raw/df_final_web_data_pt_1.txt')\n",
    "df_web_data_2 = pd.read_csv('../Data/Raw/df_final_web_data_pt_2.txt')\n",
    "df_experiment_clients = pd.read_csv('../Data/Raw/df_final_experiment_clients.txt')\n",
    "# processed data\n",
    "df_test = pd.read_csv('../Data/Cleaned_Data/df_test.csv')\n",
    "df_test_final = pd.read_csv('../Data/Cleaned_Data/df_test_final.csv')\n",
    "df_control = pd.read_csv('../Data/Cleaned_Data/df_control.csv')\n",
    "df_control_final = pd.read_csv('../Data/Cleaned_Data/df_control_final.csv')\n",
    "df_final = pd.read_csv('../Data/Cleaned_Data/df_final.csv')\n",
    "df_combined = pd.read_csv('../Data/Cleaned_Data/df_combined.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_web_data = pd.concat([df_web_data_1, df_web_data_2], ignore_index= True)\n",
    "df_test = convert_data_types_combined(df_test)\n",
    "df_test_final = convert_data_types_combined(df_test_final)\n",
    "df_control = convert_data_types_combined(df_control)\n",
    "df_control_final = convert_data_types_combined(df_control_final)\n",
    "df_final = convert_data_types_combined(df_final)\n",
    "df_combined = convert_data_types_combined(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean df_clients_profile\n",
    "df_clients_profile = print_clean_data(df_clients_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean df_experiment_clients\n",
    "df_experiment_clients = print_clean_data(df_experiment_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean df_web_data\n",
    "df_web_data = print_clean_data(df_web_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_web_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data frame with the clients that won't participe in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting aside the clients that wont be part if the experiment\n",
    "null_df_experiment_clients = df_experiment_clients[df_experiment_clients['variation'].isnull()]\n",
    "null_df_experiment_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the clients in the web data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the clients part of the test group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id of clients that are part of the test\n",
    "df_experiment_clients_Test = df_experiment_clients[df_experiment_clients['variation'] == 'Test']\n",
    "df_experiment_clients_Test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_test: combine visit_id with visitor_id and reoganize the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_Test = pd.merge(df_experiment_clients_Test, df_clients_profile, on='client_id', how='inner')\n",
    "final_df_Test = pd.merge(df_web_data, final_df_Test, on='client_id', how='inner')\n",
    "df_test = final_df_Test\n",
    "\n",
    "#change the data type to datetime\n",
    "df_test['date_time'] = pd.to_datetime(df_test['date_time']) \n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_control: combine visit_id with visitor_id and reoganize the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id of clients that are part of the control group\n",
    "df_experiment_clients_Control = df_experiment_clients[df_experiment_clients['variation'] == 'Control']\n",
    "df_experiment_clients_Control.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment_clients_Control = df_experiment_clients[df_experiment_clients['variation'] == 'Control']\n",
    "final_df_Control = pd.merge(df_experiment_clients_Control, df_clients_profile, on='client_id', how='inner')\n",
    "final_df_Control = pd.merge(df_web_data, final_df_Control, on='client_id', how='inner')\n",
    "df_control = final_df_Control\n",
    "\n",
    "#change the data type to datetime\n",
    "df_control['date_time'] = pd.to_datetime(df_control['date_time']) \n",
    "df_control.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine df_test and df_control as df_combined for comparative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_test, df_control]).reset_index(drop=True)\n",
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot and create new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_control is your DataFrame\n",
    "# 1. Data Preparation:\n",
    "df_test['date_time'] = pd.to_datetime(df_test['date_time'])\n",
    "df_test['date'] = df_test['date_time'].dt.date\n",
    "# Combine visit_id and visitor_id into a new column\n",
    "df_test['visit_visitor_id'] = df_test['visit_id'].astype(str) + \"_\" + df_test['visitor_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate time differences per step and make them positive:\n",
    "# We need to sort the dataframe before calculating the time difference\n",
    "df_test = df_test.sort_values(by=['visit_id', 'client_id', 'date_time'])\n",
    "\n",
    "df_test['next_date_time'] = df_test.groupby(['visit_id', 'client_id'])['date_time'].shift(-1)\n",
    "\n",
    "# Calculate time spent in seconds, but make sure it's always positive\n",
    "df_test['time_diff_seconds'] = (df_test['next_date_time'] - df_test['date_time']).dt.total_seconds()\n",
    "df_test['time_diff_minutes'] = df_test['time_diff_seconds'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pivot to Create Step Columns:\n",
    "df_pivot = df_test.pivot_table(index=['client_id', 'visitor_id', 'visit_id'], columns='process_step', values='time_diff_minutes', fill_value=0, aggfunc='sum')\n",
    "df_pivot = df_pivot.reset_index()\n",
    "df_pivot.columns.name = None  # Remove the 'process_step' header\n",
    "df_pivot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Rename Columns & Calculate Total Time:\n",
    "df_pivot = df_pivot.rename(columns={'confirm': 'confirm_time', 'start': 'start_time', 'step_1': 'step_1', 'step_2': 'step_2', 'step_3': 'step_3'})\n",
    "\n",
    "df_pivot['total_time_visit'] = df_pivot[['start_time', 'step_1', 'step_2', 'step_3', 'confirm_time']].sum(axis=1)\n",
    "\n",
    "# 5. Merge with Original Data and Select/Reorder Columns:\n",
    "final_df_t = pd.merge(df_pivot, df_test[['client_id', 'visit_id','variation', 'clnt_tenure_yr',\n",
    "       'clnt_tenure_mnth', 'clnt_age', 'gendr', 'num_accts', 'bal',\n",
    "       'calls_6_mnth', 'logons_6_mnth', 'date', 'process_step']], on=['client_id', 'visit_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last step per visit_id\n",
    "final_df_t['last_step'] = final_df_t.groupby('visit_id')['process_step'].transform('last')\n",
    "\n",
    "# Add new columns counting the number of times each step was visited\n",
    "step_counts = df_test.groupby(['visit_visitor_id', 'process_step']).size().unstack(fill_value=0)\n",
    "\n",
    "# Add new columns counting the number of times each step was visited\n",
    "final_df_t['visit_visitor_id'] = final_df_t['visit_id'].astype(str) + \"_\" + final_df_t['visitor_id'].astype(str)\n",
    "final_df_t['start_step'] = final_df_t['visit_visitor_id'].map(step_counts.get('start', pd.Series())).fillna(0).astype(int)\n",
    "final_df_t['1st_step'] = final_df_t['visit_visitor_id'].map(step_counts.get('step_1', pd.Series())).fillna(0).astype(int)\n",
    "final_df_t['2nd_step'] = final_df_t['visit_visitor_id'].map(step_counts.get('step_2', pd.Series())).fillna(0).astype(int)\n",
    "final_df_t['3rd_step'] = final_df_t['visit_visitor_id'].map(step_counts.get('step_3', pd.Series())).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Create completion column\n",
    "final_df_t['completion'] = final_df_t['last_step'].apply(lambda x: 1 if x == 'confirm' else 0)\n",
    "\n",
    "# Create total_navigation column\n",
    "final_df_t['navigations_bt_start_last'] =  final_df_t['1st_step'] + final_df_t['2nd_step'] + final_df_t['3rd_step'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop visit_visitor_id column if no longer needed\n",
    "final_df_t.drop(['visit_id', 'visitor_id','process_step', 'confirm_time'], axis=1, inplace=True)\n",
    "final_df_t.drop_duplicates(subset='visit_visitor_id', keep='first', inplace=True)\n",
    "# Reorder columns for better visualization\n",
    "df_test_final = final_df_t.reindex(columns=[\n",
    "    'client_id', 'visit_visitor_id', 'start_time', 'step_1', 'step_2', 'step_3', \n",
    "    'date', 'start_step', '1st_step', '2nd_step', '3rd_step', 'navigations_bt_start_last', 'last_step', 'completion',\n",
    "    'total_time_visit', 'variation', 'clnt_tenure_yr', 'clnt_tenure_mnth', \n",
    "    'clnt_age', 'gendr', 'num_accts', 'bal', 'calls_6_mnth', 'logons_6_mnth'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_control is your DataFrame\n",
    "# 1. Data Preparation:\n",
    "df_control['date_time'] = pd.to_datetime(df_control['date_time'])\n",
    "df_control['date'] = df_control['date_time'].dt.date\n",
    "# Combine visit_id and visitor_id into a new column\n",
    "df_control['visit_visitor_id'] = df_control['visit_id'].astype(str) + \"_\" + df_control['visitor_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate time differences per step and make them positive:\n",
    "# We need to sort the dataframe before calculating the time difference\n",
    "df_control = df_control.sort_values(by=['visit_id', 'client_id', 'date_time'])\n",
    "\n",
    "df_control['next_date_time'] = df_control.groupby(['visit_id', 'client_id'])['date_time'].shift(-1)\n",
    "\n",
    "# Calculate time spent in seconds, but make sure it's always positive\n",
    "df_control['time_diff_seconds'] = (df_control['next_date_time'] - df_control['date_time']).dt.total_seconds()\n",
    "df_control['time_diff_minutes'] = df_control['time_diff_seconds'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pivot to Create Step Columns:\n",
    "df_pivot_c = df_control.pivot_table(index=['client_id', 'visitor_id', 'visit_id'], columns='process_step', values='time_diff_minutes', fill_value=0, aggfunc='sum')\n",
    "df_pivot_c = df_pivot_c.reset_index()\n",
    "df_pivot_c.columns.name = None  # Remove the 'process_step' header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Rename Columns & Calculate Total Time:\n",
    "df_pivot_c = df_pivot_c.rename(columns={'confirm': 'confirm_time', 'start': 'start_time', 'step_1': 'step_1', 'step_2': 'step_2', 'step_3': 'step_3'})\n",
    "\n",
    "df_pivot_c['total_time_visit'] = df_pivot_c[['start_time', 'step_1', 'step_2', 'step_3', 'confirm_time']].sum(axis=1)\n",
    "\n",
    "# 5. Merge with Original Data and Select/Reorder Columns:\n",
    "final_df_c = pd.merge(df_pivot_c, df_control[['client_id', 'visit_id','variation', 'clnt_tenure_yr',\n",
    "       'clnt_tenure_mnth', 'clnt_age', 'gendr', 'num_accts', 'bal',\n",
    "       'calls_6_mnth', 'logons_6_mnth', 'date', 'process_step']], on=['client_id', 'visit_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last step per visit_id\n",
    "final_df_c['last_step'] = final_df_c.groupby('visit_id')['process_step'].transform('last')\n",
    "\n",
    "# Add new columns counting the number of times each step was visited\n",
    "step_counts = df_control.groupby(['visit_visitor_id', 'process_step']).size().unstack(fill_value=0)\n",
    "\n",
    "# Add new columns counting the number of times each step was visited\n",
    "final_df_c['visit_visitor_id'] = final_df_c['visit_id'].astype(str) + \"_\" + final_df_c['visitor_id'].astype(str)\n",
    "final_df_c['start_step'] = final_df_c['visit_visitor_id'].map(step_counts.get('start', pd.Series())).fillna(0).astype(int)\n",
    "final_df_c['1st_step'] = final_df_c['visit_visitor_id'].map(step_counts.get('step_1', pd.Series())).fillna(0).astype(int)\n",
    "final_df_c['2nd_step'] = final_df_c['visit_visitor_id'].map(step_counts.get('step_2', pd.Series())).fillna(0).astype(int)\n",
    "final_df_c['3rd_step'] = final_df_c['visit_visitor_id'].map(step_counts.get('step_3', pd.Series())).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Create completion column\n",
    "final_df_c['completion'] = final_df_c['last_step'].apply(lambda x: 1 if x == 'confirm' else 0)\n",
    "\n",
    "# Create total_navigation column\n",
    "\n",
    "final_df_c['navigations_bt_start_last'] = final_df_c['1st_step'] + final_df_c['2nd_step'] + final_df_c['3rd_step'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop visit_visitor_id column if no longer needed\n",
    "final_df_c.drop(['visit_id', 'visitor_id','process_step', 'confirm_time'], axis=1, inplace=True)\n",
    "final_df_c.drop_duplicates(subset='visit_visitor_id', keep='first', inplace=True)\n",
    "# Reorder columns for better visualization\n",
    "df_control_final = final_df_c.reindex(columns=[\n",
    "    'client_id', 'visit_visitor_id', 'start_time', 'step_1', 'step_2', 'step_3', \n",
    "    'date', 'start_step', '1st_step', '2nd_step', '3rd_step', 'navigations_bt_start_last', 'last_step', 'completion',\n",
    "    'total_time_visit', 'variation', 'clnt_tenure_yr', 'clnt_tenure_mnth', \n",
    "    'clnt_age', 'gendr', 'num_accts', 'bal', 'calls_6_mnth', 'logons_6_mnth'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_final.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data frames df_test_final and df_control_final as df_final for comparatrive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_test_final, df_control_final]).reset_index(drop=True)\n",
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../Data/Tableau/df_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_test_final.select_dtypes(include=[np.number]).corr()\n",
    "plt.figure(figsize=(20, 18))  # Adjust the figure size as needed\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, annot_kws={\"size\": 10})  # Adjust font size\n",
    "plt.title('Correlation Matrix', fontsize=20)  # Adjust title font size\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)  # Adjust x-axis tick labels\n",
    "plt.yticks(rotation=0, fontsize=12)  # Adjust y-axis tick labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing of variables corelated with completion variable with their corelation coefficient and p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "# function for calculating pearson correlation coefficient and p-value between 'completion' and other  'numerical variables'\n",
    "\n",
    "def calculate_correlation(df, var1, var2):\n",
    "    correlation_coef, p_value = pearsonr(df[var1], df[var2])\n",
    "    return correlation_coef, p_value\n",
    "\n",
    "# Calculate correlation coefficient and p-value for 'total_navigations' and 'completion'\n",
    "correlation_coef_tn, p_value_tn = calculate_correlation(df_final, 'navigations_bt_start_last', 'completion')\n",
    "\n",
    "# Calculate correlation coefficient and p-value for 'start_step' and 'completion'\n",
    "correlation_coef_ss, p_value_ss = calculate_correlation(df_final, 'start_step', 'completion')\n",
    "\n",
    "# Calculate correlation coefficient and p-value for 'total_time_visit' and 'completion'\n",
    "correlation_coef_ttv, p_value_ttv = calculate_correlation(df_final, 'total_time_visit', 'completion')\n",
    "\n",
    "# Calculate correlation coefficient and p-value for 'clnt_tenure_yr' and 'completion'\n",
    "correlation_coef_cty, p_value_cty = calculate_correlation(df_final, 'clnt_tenure_yr', 'completion')\n",
    "\n",
    "# Calculate correlation coefficient and p-value for 'clnt_age' and 'completion'\n",
    "correlation_coef_ca, p_value_ca = calculate_correlation(df_final, 'clnt_age', 'completion')\n",
    "\n",
    "# Calculate correlation coefficient and p-value for 'num_accts' and 'completion'\n",
    "correlation_coef_na, p_value_na = calculate_correlation(df_final, 'num_accts', 'completion')\n",
    "\n",
    "# Calculate correlation coefficient and p-value for 'calls_6_mnth' and 'completion'\n",
    "correlation_coef_c6m, p_value_c6m = calculate_correlation(df_final, 'calls_6_mnth', 'completion')\n",
    "\n",
    "# Calculate correlation coefficient and p-value for 'logons_6_mnth' and 'completion'\n",
    "correlation_coef_l6m, p_value_l6m = calculate_correlation(df_final, 'logons_6_mnth', 'completion')\n",
    "\n",
    "# Create a dictionary with the correlation coefficient and p-value for each variable\n",
    "correlation_data = {\n",
    "    'Variable': ['navigations_bt_start_last', 'start_step', 'total_time_visit', 'clnt_tenure_yr', 'clnt_age', 'num_accts', 'calls_6_mnth', 'logons_6_mnth'],\n",
    "    'Correlation Coefficient': [correlation_coef_tn, correlation_coef_ss, correlation_coef_ttv, correlation_coef_cty, correlation_coef_ca, correlation_coef_na, correlation_coef_c6m, correlation_coef_l6m],\n",
    "    'P-value': [p_value_tn, p_value_ss, p_value_ttv, p_value_cty, p_value_ca, p_value_na, p_value_c6m, p_value_l6m]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the correlation data\n",
    "correlation_table = pd.DataFrame(correlation_data)\n",
    "\n",
    "# Print the correlation table\n",
    "correlation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot (for continuous variables)\n",
    "sns.scatterplot(x='variable1', y='variable2', data=df)\n",
    "plt.title('Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot (for categorical vs continuous)\n",
    "sns.boxplot(x='categorical_variable', y='continuous_variable', data=df)\n",
    "plt.title('Box Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot (for categorical variables)\n",
    "sns.countplot(x='categorical_variable1', hue='categorical_variable2', data=df)\n",
    "plt.title('Bar Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform statistical tests to quantify the relationship between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson Correlation (for continuous variables)\n",
    "corr, p_value = pearsonr(df['variable1'], df['variable2'])\n",
    "print(f\"Pearson Correlation: {corr}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Chi-Square Test (for categorical variables)\n",
    "contingency_table = pd.crosstab(df['categorical_variable1'], df['categorical_variable2'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-Square Test: Chi2={chi2}, P-value={p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for Difference in Average Age\n",
    "Hypothesis:\n",
    "Null Hypothesis : The average age of clients engaging with the new process (Test) is the same as the average age of clients engaging with the old process (Control).\n",
    "Alternative Hypothesis : The average age of clients engaging with the new process (Test) is different from the average age of clients engaging with the old process (Control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Extract ages for each group\n",
    "test_age = df_final[df_final['variation'] == 'Test']['clnt_age']\n",
    "control_age = df_final[df_final['variation'] == 'Control']['clnt_age']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat_age, p_value_age = ttest_ind(test_age, control_age)\n",
    "print(f'Age t-statistic: {t_stat_age}, p-value: {p_value_age}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average age of clients in the Test group is not significantly different from the average age of clients in the Control group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test for Difference in Average Client Tenure\n",
    "Hypothesis:\n",
    "Null Hypothesis: The average client tenure of those engaging with the new process (Test) is the same as those engaging with the old process (Control).\n",
    "Alternative Hypothesis: The average client tenure of those engaging with the new process (Test) is different from those engaging with the old process (Control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tenures for each group\n",
    "test_tenure = df_final[df_final['variation'] == 'Test']['clnt_tenure_yr']\n",
    "control_tenure = df_final[df_final['variation'] == 'Control']['clnt_tenure_yr']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat_tenure, p_value_tenure = ttest_ind(test_tenure, control_tenure)\n",
    "print(f'Tenure t-statistic: {t_stat_tenure}, p-value: {p_value_tenure}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average tenure of clients in the Test group is not significantly different from the average tenure of clients in the Control group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Test for Gender Differences in Engagement\n",
    "Hypothesis:\n",
    "\n",
    "Null Hypothesis: Gender does not affect the likelihood of engaging with the new process (Test) or the old process (Control).\n",
    "Alternative Hypothesis: Gender affects the likelihood of engaging with the new process (Test) or the old process (Control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table_gender_process = pd.crosstab(df_final['gendr'], df_final['variation'])\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_stat_gender, p_value_gender, dof, ex = chi2_contingency(contingency_table_gender_process)\n",
    "print(contingency_table_gender_process), print(f'Chi-square statistic for gender and process: {chi2_stat_gender}, p-value: {p_value_gender}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender does not appear to have a significant effect on whether clients engage with the new process (Test) or the old process (Control)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for completion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_table = pd.crosstab(df_final['variation'], df_final['completion'])\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_stat_completion, p_value_completion, dof, ex = chi2_contingency(completion_table)\n",
    "print(f'Chi-square statistic for completion rates: {chi2_stat_completion}, p-value: {p_value_completion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The completion rates for clients engaging with the new process (Test) are statistically significantly different from those engaging with the old process (Control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_rates = df_final.groupby('variation')['completion'].mean()\n",
    "print(completion_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Hypothesis ensuring that the observed increase in completion rate from the A/B test meets or exceeds this 5% threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Completion Rates\n",
    "completion_rates = df_final.groupby('variation')['completion'].mean()\n",
    "completion_rate_test = completion_rates.get('Test', 0)\n",
    "completion_rate_control = completion_rates.get('Control', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage increase\n",
    "if completion_rate_control != 0:\n",
    "    percentage_increase = ((completion_rate_test - completion_rate_control) / completion_rate_control) * 100\n",
    "else:\n",
    "    percentage_increase = float('inf')  # Handle division by zero case\n",
    "\n",
    "print(f'Completion rate for Test group: {completion_rate_test}')\n",
    "print(f'Completion rate for Control group: {completion_rate_control}')\n",
    "print(f'Percentage increase in completion rate: {percentage_increase}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the Hypotheses:\n",
    "\n",
    "Null Hypothesis (H0): The increase in completion rate is less than 5%.\n",
    "Alternative Hypothesis (H1): The increase in completion rate is at least 5%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Two-Proportion Z-Test:\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Define number of successes (completed visits) and number of trials (total visits) for both groups\n",
    "num_success_test = df_final[df_final['variation'] == 'Test']['completion'].sum()\n",
    "num_trials_test = len(df_final[df_final['variation'] == 'Test'])\n",
    "num_success_control = df_final[df_final['variation'] == 'Control']['completion'].sum()\n",
    "num_trials_control = len(df_final[df_final['variation'] == 'Control'])\n",
    "\n",
    "# Perform the two-proportion z-test\n",
    "successes = [num_success_test, num_success_control]\n",
    "trials = [num_trials_test, num_trials_control]\n",
    "z_stat, p_value = proportions_ztest(successes, trials)\n",
    "\n",
    "print(f'Two-proportion z-test statistic: {z_stat}')\n",
    "print(f'p-value: {p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold for percentage increase\n",
    "threshold = 5.0\n",
    "\n",
    "# Check if the observed percentage increase meets or exceeds the threshold\n",
    "if percentage_increase >= threshold:\n",
    "    print('The observed increase in completion rate meets or exceeds the 5% threshold.')\n",
    "else:\n",
    "    print('The observed increase in completion rate does not meet the 5% threshold.')\n",
    "\n",
    "# Interpret the p-value\n",
    "if p_value < 0.05:\n",
    "    print('The increase in completion rate is statistically significant.')\n",
    "else:\n",
    "    print('The increase in completion rate is not statistically significant.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis on tottal time spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract total time visit for each group\n",
    "test_time = df_final[df_final['variation'] == 'Test']['total_time_visit']\n",
    "control_time = df_final[df_final['variation'] == 'Control']['total_time_visit']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat_time, p_value_time = ttest_ind(test_time, control_time)\n",
    "print(f'Total time visit t-statistic: {t_stat_time}, p-value: {p_value_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reject the null hypothesis. This suggests that there is a statistically significant difference in the total time spent on the site between clients in the Test group (new process) and clients in the Control group (old process)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis on Number of Accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hypothesis: The average number of accounts is the same for clients engaging with the new process (Test) and those engaging with the old process (Control).\n",
    "Alternative Hypothesis: The average number of accounts is different for clients engaging with the new process and those engaging with the old process.\n",
    "Test: t-Test for independent samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract number of accounts for each group\n",
    "test_accounts = df_final[df_final['variation'] == 'Test']['num_accts']\n",
    "control_accounts = df_final[df_final['variation'] == 'Control']['num_accts']\n",
    "# Perform t-test\n",
    "t_stat_accounts, p_value_accounts = ttest_ind(test_accounts, control_accounts)\n",
    "print(f'Number of accounts t-statistic: {t_stat_accounts}, p-value: {p_value_accounts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reject the null hypothesis. This indicates that there is a statistically significant difference in the number of accounts between the Test group and the Control group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: The average logons is the same for clients engaging with the new process (Test) and those engaging with the old process (Control).\n",
    "Alternative Hypothesis: The average logons is different for clients engaging with the new process and those engaging with the old process.\n",
    "Test: t-Test for independent samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logons = df_final[df_final['variation'] == 'Test']['logons_6_mnth']\n",
    "control_logons = df_final[df_final['variation'] == 'Control']['logons_6_mnth']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat_balances, p_value_balances = ttest_ind(test_logons, control_logons)\n",
    "print(f'Balance t-statistic: {t_stat_balances}, p-value: {p_value_balances}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Reject the null hypothesis. This implies that there is a statistically difference in the average balance between the Test group (new process) and the Control group (old process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_balance_test = df_final[df_final['variation'] == 'Test']['bal'].mean()\n",
    "average_balance_control = df_final[df_final['variation'] == 'Control']['bal'].mean()\n",
    "\n",
    "print(f'Average balance for Test group: {average_balance_test}')\n",
    "print(f'Average balance for Control group: {average_balance_control}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract recent call activity for each group\n",
    "test_calls = df_final[df_final['variation'] == 'Test']['calls_6_mnth']\n",
    "control_calls = df_final[df_final['variation'] == 'Control']['calls_6_mnth']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat_calls, p_value_calls = ttest_ind(test_calls, control_calls)\n",
    "print(f'Calls in last 6 months t-statistic: {t_stat_calls}, p-value: {p_value_calls}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reject the null hypothesis. This means that there is a statistically significant difference in the number of calls in the last 6 months between the Test group (new process) and the Control group (old process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_navigations = df_final[df_final['variation'] == 'Test']['navigations_bt_start_last']\n",
    "control_navigations = df_final[df_final['variation'] == 'Control']['navigations_bt_start_last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat_navigations, p_value_navigations = ttest_ind(test_navigations, control_navigations)\n",
    "print(f'Navigations between start and last t-statistic: {t_stat_navigations}, p-value: {p_value_navigations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reject the null hypothesis. This means that there is a statistically significant difference in the number of navigations between the Test and Control groups.\n",
    "\n",
    "Contextualize Findings:\n",
    "If the Test group has more navigations: This might indicate increased user activity or engagement with the new process.\n",
    "If the Test group has fewer navigations: This could suggest that the new process is more efficient or requires fewer steps.\n",
    "Needs further investigations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing for error rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "\n",
    "Null Hypothesis (H0): There is no significant difference in the error rates between the Test and Control groups.\n",
    "Alternative Hypothesis (H1): There is a significant difference in the error rates between the Test and Control groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Example DataFrame creation (replace with actual data loading code)\n",
    "# df_combined = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Convert date_time to pandas datetime format\n",
    "df_combined['date_time'] = pd.to_datetime(df_combined['date_time'])\n",
    "\n",
    "# Sort by client_id and date_time\n",
    "df_combined = df_combined.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Calculate the time difference to the previous step\n",
    "df_combined['time_to_previous_step'] = df_combined.groupby('client_id')['date_time'].diff().dt.total_seconds()\n",
    "\n",
    "# Identify errors: going back to any previous step in less than 30 seconds\n",
    "df_combined['is_error'] = df_combined['time_to_previous_step'] < 30\n",
    "\n",
    "# Count errors and non-errors\n",
    "errors_test = df_combined[(df_combined['variation'] == 'Test') & (df_combined['is_error'])].shape[0]\n",
    "non_errors_test = df_combined[(df_combined['variation'] == 'Test') & (~df_combined['is_error'])].shape[0]\n",
    "\n",
    "errors_control = df_combined[(df_combined['variation'] == 'Control') & (df_combined['is_error'])].shape[0]\n",
    "non_errors_control = df_combined[(df_combined['variation'] == 'Control') & (~df_combined['is_error'])].shape[0]\n",
    "\n",
    "# Calculate total observations for each group\n",
    "total_test = errors_test + non_errors_test\n",
    "total_control = errors_control + non_errors_control\n",
    "\n",
    "# Compute error rates\n",
    "error_rate_test = errors_test / total_test if total_test > 0 else 0\n",
    "error_rate_control = errors_control / total_control if total_control > 0 else 0\n",
    "\n",
    "# Print error rates\n",
    "print(f'Error rate for Test group: {error_rate_test:.4f}')\n",
    "print(f'Error rate for Control group: {error_rate_control:.4f}')\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = [\n",
    "    [errors_test, non_errors_test],  # Test group\n",
    "    [errors_control, non_errors_control]  # Control group\n",
    "]\n",
    "\n",
    "# Perform the Chi-Square test\n",
    "chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f'Chi-square statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}')\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference in error rates between the Test and Control groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference in error rates between the Test and Control groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a scatter plot with lines for error rate vs. completion rate\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line+scatter for test data error rate\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=error_rate_test.index,\n",
    "    y=error_rate_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data Error Rate',\n",
    "    line=dict(shape='linear', color='red')\n",
    "))\n",
    "\n",
    "# Line+scatter for test data completion rate\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=completion_rate_test.index,\n",
    "    y=completion_rate_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data Completion Rate',\n",
    "    line=dict(shape='linear', color='blue')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data error rate\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=error_rate_control.index,\n",
    "    y=error_rate_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data Error Rate',\n",
    "    line=dict(shape='linear', color='orange')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data completion rate\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=completion_rate_control.index,\n",
    "    y=completion_rate_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data Completion Rate',\n",
    "    line=dict(shape='linear', color='green')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Completion Rate vs. Error Rate (Test and Control Data)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Rate',\n",
    "    yaxis_tickformat=',.0%',\n",
    "    legend_title_text='Rate Type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "filtered_df = df_test_final[df_test_final['navigations_bt_start_last'] <= 30]\n",
    "\n",
    "# Calculate the frequency of 'total_navigations' for 'completion' values 0 and 1\n",
    "freq_completion_0 = filtered_df[filtered_df['completion'] == 0]['navigations_bt_start_last'].value_counts().sort_index()\n",
    "freq_completion_1 = filtered_df[filtered_df['completion'] == 1]['navigations_bt_start_last'].value_counts().sort_index()\n",
    "\n",
    "# Create a line graph\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line for completion = 0\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=freq_completion_0.index,\n",
    "    y=freq_completion_0.values,\n",
    "    mode='lines+markers',\n",
    "    name='Completion = 0',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Line for completion = 1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=freq_completion_1.index,\n",
    "    y=freq_completion_1.values,\n",
    "    mode='lines+markers',\n",
    "    name='Completion = 1',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Frequency of Total Navigations for Completion = 0 and 1',\n",
    "    xaxis_title='navigations_bt_start_last',\n",
    "    yaxis_title='Frequency',\n",
    "    legend_title_text='Completion'\n",
    ")\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_control = df_control_final[df_control_final['navigations_bt_start_last'] <= 10]\n",
    "\n",
    "# Calculate the frequency of 'total_navigations' for 'completion' values 0 and 1\n",
    "freq_completion_0 = filtered_df_control[filtered_df_control['completion'] == 0]['navigations_bt_start_last'].value_counts().sort_index()\n",
    "freq_completion_1 = filtered_df_control[filtered_df_control['completion'] == 1]['navigations_bt_start_last'].value_counts().sort_index()\n",
    "\n",
    "# Create a line graph\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line for completion = 0\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=freq_completion_0.index,\n",
    "    y=freq_completion_0.values,\n",
    "    mode='lines+markers',\n",
    "    name='Completion = 0',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Line for completion = 1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=freq_completion_1.index,\n",
    "    y=freq_completion_1.values,\n",
    "    mode='lines+markers',\n",
    "    name='Completion = 1',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Frequency of Total Navigations for Completion = 0 and 1',\n",
    "    xaxis_title='navigations_bt_start_last',\n",
    "    yaxis_title='Frequency',\n",
    "    legend_title_text='Completion'\n",
    ")\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_freq_melted.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_final[(df_final['navigations_bt_start_last'] <= 30) & (df_final['completion'] == 1)]\n",
    "\n",
    "# Calculate the frequency of 'navigations_bt_start_last' for each variation\n",
    "freq = filtered_df.groupby('variation')['navigations_bt_start_last'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Normalize the frequencies\n",
    "norm_freq = freq.div(freq.sum(axis=1), axis=0)\n",
    "\n",
    "# Reset index for plotting\n",
    "norm_freq = norm_freq.reset_index()\n",
    "\n",
    "# Melt DataFrame for easier plotting\n",
    "norm_freq_melted = norm_freq.melt(id_vars='variation', var_name='Navigations', value_name='Normalized Frequency')\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for each variation\n",
    "for variation in norm_freq_melted['variation'].unique():\n",
    "    df_variation = norm_freq_melted[norm_freq_melted['variation'] == variation]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_variation['Navigations'],\n",
    "        y=df_variation['Normalized Frequency'],\n",
    "        mode='lines+markers',\n",
    "        name=variation\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Total Navigations done bteween start and last page by ussrs who completed the process',\n",
    "    xaxis_title='Navigations',\n",
    "    yaxis_title='Normalized Frequency',\n",
    "    legend_title='variation',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['date'] = pd.to_datetime(df_test_final['date'])\n",
    "df_control_final['date'] = pd.to_datetime(df_control_final['date'])\n",
    "\n",
    "# Filter data for the first month\n",
    "start_date = df_test_final['date'].min()\n",
    "end_date = start_date + pd.DateOffset(days=30)\n",
    "\n",
    "filtered_test_df = df_test_final[(df_test_final['date'] >= start_date) & (df_test_final['date'] < end_date)]\n",
    "filtered_control_df = df_control_final[(df_control_final['date'] >= start_date) & (df_control_final['date'] < end_date)]\n",
    "\n",
    "# Calculate daily completion rate for test data\n",
    "daily_completion_test = filtered_test_df.groupby(filtered_test_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Calculate daily completion rate for control data\n",
    "daily_completion_control = filtered_control_df.groupby(filtered_control_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Create a line+scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line+scatter for test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_test.index,\n",
    "    y=daily_completion_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_control.index,\n",
    "    y=daily_completion_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Daily Completion Rate for Test and Control Data (First Month)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Completion Rate',\n",
    "    yaxis_tickformat=',.0%',\n",
    "    legend_title_text='Data Source'\n",
    ")\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['date'] = pd.to_datetime(df_test_final['date'])\n",
    "df_control_final['date'] = pd.to_datetime(df_control_final['date'])\n",
    "\n",
    "# Calculate the start and end dates for the second month\n",
    "start_date = df_test_final['date'].min()\n",
    "end_first_month = start_date + pd.DateOffset(days=30)\n",
    "start_second_month = end_first_month\n",
    "end_second_month = start_second_month + pd.DateOffset(days=30)\n",
    "\n",
    "# Filter data for the second month\n",
    "filtered_test_df = df_test_final[(df_test_final['date'] >= start_second_month) & (df_test_final['date'] < end_second_month)]\n",
    "filtered_control_df = df_control_final[(df_control_final['date'] >= start_second_month) & (df_control_final['date'] < end_second_month)]\n",
    "\n",
    "# Calculate daily completion rate for test data\n",
    "daily_completion_test = filtered_test_df.groupby(filtered_test_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Calculate daily completion rate for control data\n",
    "daily_completion_control = filtered_control_df.groupby(filtered_control_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Create a line+scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line+scatter for test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_test.index,\n",
    "    y=daily_completion_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_control.index,\n",
    "    y=daily_completion_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Daily Completion Rate for Test and Control Data (Second Month)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Completion Rate',\n",
    "    yaxis_tickformat=',.0%',\n",
    "    legend_title_text='Data Source'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['date'] = pd.to_datetime(df_test_final['date'])\n",
    "df_control_final['date'] = pd.to_datetime(df_control_final['date'])\n",
    "\n",
    "# Calculate the start and end dates for the third month\n",
    "start_date = df_test_final['date'].min()\n",
    "end_first_month = start_date + pd.DateOffset(days=30)\n",
    "start_second_month = end_first_month\n",
    "end_second_month = start_second_month + pd.DateOffset(days=30)\n",
    "start_third_month = end_second_month\n",
    "end_third_month = start_third_month + pd.DateOffset(days=30)\n",
    "\n",
    "# Filter data for the third month\n",
    "filtered_test_df = df_test_final[(df_test_final['date'] >= start_third_month) & (df_test_final['date'] < end_third_month)]\n",
    "filtered_control_df = df_control_final[(df_control_final['date'] >= start_third_month) & (df_control_final['date'] < end_third_month)]\n",
    "\n",
    "# Calculate daily completion rate for test data\n",
    "daily_completion_test = filtered_test_df.groupby(filtered_test_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Calculate daily completion rate for control data\n",
    "daily_completion_control = filtered_control_df.groupby(filtered_control_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Create a line+scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line+scatter for test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_test.index,\n",
    "    y=daily_completion_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_control.index,\n",
    "    y=daily_completion_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Daily Completion Rate for Test and Control Data (Third Month)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Completion Rate',\n",
    "    yaxis_tickformat=',.0%',\n",
    "    legend_title_text='Data Source'\n",
    ")\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['date'] = pd.to_datetime(df_test_final['date'])\n",
    "df_control_final['date'] = pd.to_datetime(df_control_final['date'])\n",
    "\n",
    "# Calculate the start and end dates for the three months\n",
    "start_date = df_test_final['date'].min()\n",
    "end_third_month = start_date + pd.DateOffset(days=90)\n",
    "\n",
    "# Filter data for the three months\n",
    "filtered_test_df = df_test_final[(df_test_final['date'] >= start_date) & (df_test_final['date'] < end_third_month)]\n",
    "filtered_control_df = df_control_final[(df_control_final['date'] >= start_date) & (df_control_final['date'] < end_third_month)]\n",
    "\n",
    "# Calculate daily completion rate for test data\n",
    "daily_completion_test = filtered_test_df.groupby(filtered_test_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Calculate daily completion rate for control data\n",
    "daily_completion_control = filtered_control_df.groupby(filtered_control_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Create a line+scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line+scatter for test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_test.index,\n",
    "    y=daily_completion_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data',\n",
    "    line=dict(shape='linear', color='blue')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_control.index,\n",
    "    y=daily_completion_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data',\n",
    "    line=dict(shape='linear', color='red')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Daily Completion Rate for Test and Control Data (Three Months)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Completion Rate',\n",
    "    yaxis_tickformat=',.0%',\n",
    "    legend_title_text='Data Source'\n",
    ")\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['date'] = pd.to_datetime(df_test_final['date'])\n",
    "df_control_final['date'] = pd.to_datetime(df_control_final['date'])\n",
    "\n",
    "# Filter data where total_navigations is 3\n",
    "filtered_test_df = df_test_final[df_test_final['navigations_bt_start_last'] == 3]\n",
    "filtered_control_df = df_control_final[df_control_final['navigations_bt_start_last'] == 3]\n",
    "\n",
    "# Calculate daily completion rate for test data where total_navigations is 3\n",
    "daily_completion_test = filtered_test_df.groupby(filtered_test_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Calculate daily completion rate for control data where total_navigations is 3\n",
    "daily_completion_control = filtered_control_df.groupby(filtered_control_df['date'].dt.date)['completion'].mean()\n",
    "\n",
    "# Create a line+scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line+scatter for test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_test.index,\n",
    "    y=daily_completion_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data',\n",
    "    line=dict(shape='linear', color='blue')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_completion_control.index,\n",
    "    y=daily_completion_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data',\n",
    "    line=dict(shape='linear', color='red')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Daily Completion Rate for Test and Control Data (Total Navigations = 3)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Completion Rate',\n",
    "    yaxis_tickformat=',.0%',\n",
    "    legend_title_text='Data Source'\n",
    ")\n",
    "\n",
    "# Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['date'] = pd.to_datetime(df_test_final['date'])\n",
    "df_control_final['date'] = pd.to_datetime(df_control_final['date'])\n",
    "\n",
    "# Filter data where total_navigations is 3\n",
    "filtered_test_df = df_test_final[df_test_final['total_steps'] == 5]\n",
    "filtered_control_df = df_control_final[df_control_final['total_steps'] == 5]\n",
    "\n",
    "# Count occurrences of total_navigations = 3 by date for test data\n",
    "counts_test = filtered_test_df.groupby(filtered_test_df['date'].dt.date).size()\n",
    "\n",
    "# Count occurrences of total_navigations = 3 by date for control data\n",
    "counts_control = filtered_control_df.groupby(filtered_control_df['date'].dt.date).size()\n",
    "\n",
    "# Create a line+scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line+scatter for test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=counts_test.index,\n",
    "    y=counts_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data',\n",
    "    line=dict(shape='linear', color='blue')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=counts_control.index,\n",
    "    y=counts_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data',\n",
    "    line=dict(shape='linear', color='red')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Frequency of Total steps taken = 5 by Date',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Frequency of Total steps taken = 5',\n",
    "    legend_title_text='Data Source'\n",
    ")\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['date_time'] = pd.to_datetime(df_test['date_time'])\n",
    "df_control['date_time'] = pd.to_datetime(df_control['date_time'])\n",
    "\n",
    "# Function to calculate error rate and completion rate\n",
    "def calculate_rates(df):\n",
    "    # Sort the dataframe by 'visit_id' and 'date_time'\n",
    "    df = df.sort_values(by=['visit_id', 'date_time'])\n",
    "    \n",
    "    # Calculate the time difference between steps\n",
    "    df['time_diff'] = df.groupby('visit_id')['date_time'].diff().dt.total_seconds()\n",
    "    \n",
    "    # Identify completions (where process step is 'confirm')\n",
    "    df['completion'] = df['process_step'] == 'confirm'\n",
    "    \n",
    "    # Convert 'process_step' to a category type and then to codes for numerical comparison\n",
    "    df['process_step_code'] = df['process_step'].astype('category').cat.codes\n",
    "    \n",
    "    # Identify errors (going back to the previous step in less than 5 seconds)\n",
    "    df['error'] = (df['time_diff'] < 30) & (df['process_step_code'].diff() < 0)\n",
    "    \n",
    "    # Calculate the daily error rate\n",
    "    error_rate = df.groupby(df['date_time'].dt.date)['error'].mean()\n",
    "    \n",
    "    # Calculate the daily completion rate\n",
    "    completion_rate = df.groupby(df['date_time'].dt.date)['completion'].mean()\n",
    "    \n",
    "    return error_rate, completion_rate\n",
    "\n",
    "# Calculate rates for test data\n",
    "error_rate_test, completion_rate_test = calculate_rates(df_test)\n",
    "\n",
    "# Calculate rates for control data\n",
    "error_rate_control, completion_rate_control = calculate_rates(df_control)\n",
    "\n",
    "# Create a scatter plot with lines for error rate vs. completion rate\n",
    "fig = go.Figure()\n",
    "\n",
    "# Line+scatter for test data error rate\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=error_rate_test.index,\n",
    "    y=error_rate_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data Error Rate',\n",
    "    line=dict(shape='linear', color='red')\n",
    "))\n",
    "\n",
    "# Line+scatter for test data completion rate\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=completion_rate_test.index,\n",
    "    y=completion_rate_test.values,\n",
    "    mode='lines+markers',\n",
    "    name='Test Data Completion Rate',\n",
    "    line=dict(shape='linear', color='blue')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data error rate\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=error_rate_control.index,\n",
    "    y=error_rate_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data Error Rate',\n",
    "    line=dict(shape='linear', color='orange')\n",
    "))\n",
    "\n",
    "# Line+scatter for control data completion rate\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=completion_rate_control.index,\n",
    "    y=completion_rate_control.values,\n",
    "    mode='lines+markers',\n",
    "    name='Control Data Completion Rate',\n",
    "    line=dict(shape='linear', color='green')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Completion Rate vs. Error Rate (Test and Control Data)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Rate',\n",
    "    yaxis_tickformat=',.0%',\n",
    "    legend_title_text='Rate Type'\n",
    ")\n",
    "\n",
    "# Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df, variable, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[variable], kde=False, discrete=True, bins=range(df[variable].max() + 1))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(variable)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Plot distribution for total navigations in both test and control datasets\n",
    "plot_distribution(df_test_final, 'total_navigations', 'Distribution of Total Navigations (Test Data)')\n",
    "plot_distribution(df_control_final, 'total_navigations', 'Distribution of Total Navigations (Control Data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Check normality for total_navigations\n",
    "stat, p = shapiro(df_test_final['total_navigations'])\n",
    "print('Shapiro-Wilk Test: Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "if p > 0.05:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "# Spearman correlation for test data\n",
    "spearman_corr, spearman_p = spearmanr(df_test_final['total_navigations'], df_test_final['completion'])\n",
    "print(f'Spearman correlation: {spearman_corr}, p-value: {spearman_p}')\n",
    "\n",
    "# Kendall's Tau correlation for test data\n",
    "kendall_corr, kendall_p = kendalltau(df_test_final['total_navigations'], df_test_final['completion'])\n",
    "print(f'Kendall Tau correlation: {kendall_corr}, p-value: {kendall_p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_test_final['total_navigations'], kde=False, discrete=True)\n",
    "plt.title('Histogram of Total Navigations')\n",
    "plt.xlabel('Total Navigations')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot box plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=df_test_final['total_navigations'])\n",
    "plt.title('Box Plot of Total Navigations')\n",
    "plt.xlabel('Total Navigations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation\n",
    "df_test_final['log_total_navigations'] = np.log1p(df_test_final['total_navigations'])\n",
    "\n",
    "# Check normality again after transformation\n",
    "stat, p = shapiro(df_test_final['log_total_navigations'])\n",
    "print('Shapiro-Wilk Test after Log Transformation: Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "if p > 0.05:\n",
    "    print('Transformed sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Transformed sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def plot_histogram(data, column, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data[column], kde=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Q-Q Plot\n",
    "def plot_qqplot(data, column, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    stats.probplot(data[column], dist=\"norm\", plot=plt)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Box Plot\n",
    "def plot_boxplot(data, column, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=data[column])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column)\n",
    "    plt.show()\n",
    "\n",
    "# Plot for 'total_navigations'\n",
    "plot_histogram(df_test_final, 'total_navigations', 'Histogram of Total Navigations (Test Data)')\n",
    "plot_qqplot(df_test_final, 'total_navigations', 'Q-Q Plot of Total Navigations (Test Data)')\n",
    "plot_boxplot(df_test_final, 'total_navigations', 'Box Plot of Total Navigations (Test Data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapiro_wilk_test(data, column):\n",
    "    stat, p = stats.shapiro(data[column])\n",
    "    print(f'Shapiro-Wilk Test for {column}: Statistics={stat}, p-value={p}')\n",
    "    if p > 0.05:\n",
    "        print(f'{column} looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print(f'{column} does not look Gaussian (reject H0)')\n",
    "\n",
    "# Kolmogorov-Smirnov Test\n",
    "def kolmogorov_smirnov_test(data, column):\n",
    "    stat, p = stats.kstest(data[column], 'norm', args=(data[column].mean(), data[column].std()))\n",
    "    print(f'Kolmogorov-Smirnov Test for {column}: Statistics={stat}, p-value={p}')\n",
    "    if p > 0.05:\n",
    "        print(f'{column} looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print(f'{column} does not look Gaussian (reject H0)')\n",
    "\n",
    "# Anderson-Darling Test\n",
    "def anderson_darling_test(data, column):\n",
    "    result = stats.anderson(data[column])\n",
    "    print(f'Anderson-Darling Test for {column}: Statistic={result.statistic}')\n",
    "    for i in range(len(result.critical_values)):\n",
    "        sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "        if result.statistic < cv:\n",
    "            print(f'{sl}%: {column} looks Gaussian (fail to reject H0)')\n",
    "        else:\n",
    "            print(f'{sl}%: {column} does not look Gaussian (reject H0)')\n",
    "\n",
    "# D'Agostino's K-squared Test\n",
    "def dagostino_test(data, column):\n",
    "    stat, p = stats.normaltest(data[column])\n",
    "    print(f'D\\'Agostino\\'s K-squared Test for {column}: Statistics={stat}, p-value={p}')\n",
    "    if p > 0.05:\n",
    "        print(f'{column} looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print(f'{column} does not look Gaussian (reject H0)')\n",
    "\n",
    "# Apply tests for 'total_navigations'\n",
    "shapiro_wilk_test(df_test_final, 'total_navigations')\n",
    "kolmogorov_smirnov_test(df_test_final, 'total_navigations')\n",
    "anderson_darling_test(df_test_final, 'total_navigations')\n",
    "dagostino_test(df_test_final, 'total_navigations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_test_final['total_navigations'], kde=True)\n",
    "plt.title('Original Data')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_test_final['log_total_navigations'], kde=True)\n",
    "plt.title('Log Transformed Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step EDA for numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_test_final['navigations_bt_start_last'], kde=True)\n",
    "plt.show()\n",
    "sns.boxplot(df_test_final['navigations_bt_start_last'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "shapiro_test = shapiro(df_test_final['total_navigations'])\n",
    "print(shapiro_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "z_scores = stats.zscore(df_test_final['total_navigations'])\n",
    "outliers = np.where(np.abs(z_scores) > 3)\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = df_test_final['total_navigations'].skew()\n",
    "kurtosis = df_test_final['total_navigations'].kurt()\n",
    "print(f\"Skewness: {skewness}, Kurtosis: {kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['log_total_navigations'] = np.log(df_test_final['total_navigations'] + 1)\n",
    "sns.histplot(df_test_final['log_total_navigations'], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['sqrt_total_navigations'] = np.sqrt(df_test_final['total_navigations'])\n",
    "\n",
    "# Check distribution of square root-transformed total_navigations\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_test_final['sqrt_total_navigations'], kde=True)\n",
    "plt.title('Histogram of Square Root-Transformed Total Navigations')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(df_test_final['sqrt_total_navigations'], dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Square Root-Transformed Total Navigations')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Perform Shapiro-Wilk test for normality on square root-transformed data\n",
    "shapiro_test_sqrt = stats.shapiro(df_test_final['sqrt_total_navigations'])\n",
    "print(f'Shapiro-Wilk Test on Square Root-Transformed Data: Statistic={shapiro_test_sqrt.statistic}, p-value={shapiro_test_sqrt.pvalue}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['yeojohnson_total_navigations'], fitted_lambda = stats.yeojohnson(df_test_final['total_navigations'])\n",
    "\n",
    "# Check distribution of Yeo-Johnson transformed total_navigations\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_test_final['yeojohnson_total_navigations'], kde=True)\n",
    "plt.title('Histogram of Yeo-Johnson Transformed Total Navigations')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(df_test_final['yeojohnson_total_navigations'], dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Yeo-Johnson Transformed Total Navigations')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Perform Shapiro-Wilk test for normality on Yeo-Johnson transformed data\n",
    "shapiro_test_yeojohnson = stats.shapiro(df_test_final['yeojohnson_total_navigations'])\n",
    "print(f'Shapiro-Wilk Test on Yeo-Johnson Transformed Data: Statistic={shapiro_test_yeojohnson.statistic}, p-value={shapiro_test_yeojohnson.pvalue}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_statistic(data, n_iterations=1000, stat_function=np.mean):\n",
    "    bootstrapped_stats = np.empty(n_iterations)\n",
    "    for i in range(n_iterations):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrapped_stats[i] = stat_function(sample)\n",
    "    return bootstrapped_stats\n",
    "\n",
    "# Bootstrapping the mean of total navigations\n",
    "bootstrapped_means = bootstrap_statistic(df_test_final['total_navigations'].dropna())\n",
    "\n",
    "# Calculate confidence intervals\n",
    "confidence_interval = np.percentile(bootstrapped_means, [2.5, 97.5])\n",
    "print(\"95% Confidence Interval for the mean of total navigations:\", confidence_interval)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "sns.histplot(df_test_final['total_navigations'], ax=axes[0], kde=True)\n",
    "axes[0].set_title('Original Data')\n",
    "\n",
    "sns.histplot(np.log1p(df_test_final['total_navigations']), ax=axes[1], kde=True)\n",
    "axes[1].set_title('Log-Transformed Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_statistic(data, n_iterations=1000, stat_function=np.mean):\n",
    "    bootstrapped_stats = np.empty(n_iterations)\n",
    "    for i in range(n_iterations):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrapped_stats[i] = stat_function(sample)\n",
    "    return bootstrapped_stats\n",
    "\n",
    "# Calculate bootstrapped means\n",
    "bootstrapped_means = bootstrap_statistic(df_test_final['total_navigations'].dropna())\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "confidence_interval = np.percentile(bootstrapped_means, [2.5, 97.5])\n",
    "print(\"95% Confidence Interval for the mean of total navigations:\", confidence_interval)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of bootstrapped means\n",
    "sns.histplot(bootstrapped_means, kde=True)\n",
    "plt.axvline(confidence_interval[0], color='red', linestyle='--', label=f'Lower 95% CI: {confidence_interval[0]:.2f}')\n",
    "plt.axvline(confidence_interval[1], color='red', linestyle='--', label=f'Upper 95% CI: {confidence_interval[1]:.2f}')\n",
    "plt.title('Bootstrapped Means of Total Navigations')\n",
    "plt.xlabel('Mean of Total Navigations')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = shapiro(df_test_final['total_navigations'].dropna())\n",
    "print(f'Statistic: {stat}, P-value: {p}')\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stats.probplot(df_test_final['total_navigations'], dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_mean(data, n_iterations=1000):\n",
    "    boot_means = np.empty(n_iterations)\n",
    "    for i in range(n_iterations):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        boot_means[i] = np.mean(sample)\n",
    "    return boot_means\n",
    "\n",
    "# Bootstrapped means for total_navigations\n",
    "boot_means = bootstrap_mean(df_test_final['total_navigations'].dropna())\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "ci_low, ci_high = np.percentile(boot_means, [2.5, 97.5])\n",
    "print(f'95% Confidence Interval for the mean of total navigations: [{ci_low}, {ci_high}]')\n",
    "\n",
    "# Plotting the bootstrapped means\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(boot_means, kde=True)\n",
    "plt.axvline(ci_low, color='red', linestyle='--', label=f'Lower 95% CI: {ci_low:.2f}')\n",
    "plt.axvline(ci_high, color='red', linestyle='--', label=f'Upper 95% CI: {ci_high:.2f}')\n",
    "plt.title('Bootstrapped Means of Total Navigations')\n",
    "plt.xlabel('Mean of Total Navigations')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = stats.zscore(df_test_final['total_time_visit'])\n",
    "abs_z_scores = abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3)  # Remove entries with z-score > 3\n",
    "df_no_outliers = df_test_final[filtered_entries]\n",
    "\n",
    "# Creating the violin plot without outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='completion', y='total_time_visit', data=df_no_outliers)\n",
    "plt.title('Violin Plot of Total Navigations by Category (Outliers Removed)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers['log_total_navigations'] = np.log1p(df_no_outliers['total_time_visit'])\n",
    "\n",
    "# Creating the violin plot with transformed data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='completion', y='total_time_visit', data=df_no_outliers)\n",
    "plt.title('Violin Plot of Log Transformed Total Navigations by Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(df_test_final['navigations_bt_start_last']))\n",
    "\n",
    "# Define the threshold for identifying outliers\n",
    "threshold = 3\n",
    "\n",
    "# Get a boolean array indicating if each point is an outlier\n",
    "outliers = z_scores > threshold\n",
    "\n",
    "# Filter out the outliers\n",
    "df_test_final_no_outliers = df_test_final[~outliers]\n",
    "\n",
    "# Plotting the cleaned data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(df_test_final_no_outliers['navigations_bt_start_last'], kde=True)\n",
    "plt.title('Distribution of Total Navigations After Removing Outliers')\n",
    "plt.xlabel('navigations_bt_start_last')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_test_final['navigations_bt_start_last'].quantile(0.25)\n",
    "Q3 = df_test_final['navigations_bt_start_last'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the bounds for identifying outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the outliers\n",
    "df_test_final_no_outliers = df_test_final[(df_test_final['navigations_bt_start_last'] >= lower_bound) & \n",
    "                                          (df_test_final['navigations_bt_start_last'] <= upper_bound)]\n",
    "\n",
    "# Plotting the cleaned data\n",
    "sns.histplot(df_test_final_no_outliers['navigations_bt_start_last'], kde=True)\n",
    "plt.title('Distribution of Total Navigations After Removing Outliers')\n",
    "plt.xlabel('Total Navigations')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Experiment Design Evaluation with Visualizations\n",
    "def experiment_evaluation_with_visualizations(df_control, df_test):\n",
    "    control_size = df_control['visit_visitor_id'].nunique()\n",
    "    test_size = df_test['visit_visitor_id'].nunique()\n",
    "\n",
    "    print(\"Control Group Size:\", control_size)\n",
    "    print(\"Test Group Size:\", test_size)\n",
    "\n",
    "    # Plot Group Sizes\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(['Control', 'Test'], [control_size, test_size], color=['blue', 'orange'])\n",
    "    plt.title('Group Sizes')\n",
    "    plt.ylabel('Number of Unique Visitors')\n",
    "    plt.show()\n",
    "\n",
    "    # Gender Distribution\n",
    "    gender_dist_control = df_control['gendr'].value_counts(normalize=True)\n",
    "    gender_dist_test = df_test['gendr'].value_counts(normalize=True)\n",
    "\n",
    "    print(\"Gender Distribution Control:\\n\", gender_dist_control)\n",
    "    print(\"Gender Distribution Test:\\n\", gender_dist_test)\n",
    "\n",
    "    # Plot Gender Distribution\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axs[0].pie(gender_dist_control, labels=gender_dist_control.index, autopct='%1.1f%%', colors=['lightblue', 'lightgreen'])\n",
    "    axs[0].set_title('Gender Distribution - Control Group')\n",
    "\n",
    "    axs[1].pie(gender_dist_test, labels=gender_dist_test.index, autopct='%1.1f%%', colors=['lightcoral', 'lightskyblue'])\n",
    "    axs[1].set_title('Gender Distribution - Test Group')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "experiment_evaluation_with_visualizations(df_control_final, df_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Data Needs\n",
    "print(\"Additional data that could enhance the analysis:\")\n",
    "print(\"- Detailed logs of user interactions (e.g., clicks, hovers)\")\n",
    "print(\"- Feedback or survey data on user satisfaction\")\n",
    "print(\"- Data on external factors that could influence user behavior (e.g., marketing campaigns)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
